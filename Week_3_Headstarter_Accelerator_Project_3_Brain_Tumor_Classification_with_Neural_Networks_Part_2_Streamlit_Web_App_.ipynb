{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMtgIg4FCIW9m3PdjWLcb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AslauAlexandru/Week-3-Headstarter-Accelerator-Project-3-Brain-Tumor-Classification-with-Neural-Networks/blob/main/Week_3_Headstarter_Accelerator_Project_3_Brain_Tumor_Classification_with_Neural_Networks_Part_2_Streamlit_Web_App_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 Headstarter Accelerator Project 3: Brain Tumor Classification with Neural Networks - Part 2: Streamlit Web App"
      ],
      "metadata": {
        "id": "ScKBy69AjsWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week 3 Headstarter Accelerator Project 3: Brain Tumor Classification with Neural Networks\n",
        "\n",
        "In this project, you will learn how to train neural networks to classify tumors in brain MRI scans. You will learn about how to construct different neural network architectures through transfer learning and custom convolutional layers, and use the Gemini 1.5 Flash model to generate explanations for the model's predictions."
      ],
      "metadata": {
        "id": "fq1_KlWIkKch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Streamlit Web App"
      ],
      "metadata": {
        "id": "N8OILVX6kO__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive at /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Your desired mountpoint within Google Drive\n",
        "mountpoint = '/content/drive/MyDrive'\n",
        "\n",
        "# Check if the mountpoint exists, and create it if necessary\n",
        "import os\n",
        "if not os.path.exists(mountpoint):\n",
        "  os.makedirs(mountpoint)\n",
        "\n",
        "# You can now access files within your Google Drive using the mountpoint\n",
        "# For example, to list files in your MyDrive folder:\n",
        "!ls '{mountpoint}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rThC9u-6lreB",
        "outputId": "a8afefba-4e0c-4632-ddcc-47df8c0b5e9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'Colab Notebooks'\t\t W3_Headstarter_Acc_P3_Brain_Tumor_Classific_NNs_h5\n",
            "'Copy of ACV scheduler.gsheet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RClYER5ErRTA",
        "outputId": "3479a951-5b60-4742-d38d-189d4499ef5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.12.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.12.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmRvt5RijC1z",
        "outputId": "b2371cdd-a82b-442e-8d91-7aa1d1feb431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, smmap, python-dotenv, pyngrok, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 pyngrok-7.2.1 python-dotenv-1.0.1 smmap-5.0.1 streamlit-1.40.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "! pip install streamlit pyngrok python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title dotenv\n",
        "%%writefile /content/.env\n",
        "GOOGLE_API_KEY=AIzaSyBQP_bjm6karXRTnmU2AbQAT5pv4Vn8LNg\n",
        "GROQ_API_KEY=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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "399L4pYCkluT",
        "outputId": "3d22dbbc-2f72-4d11-cedc-3aa6f6d02bf9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "fadPlG9CklzY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LILUfJiCkl1k",
        "outputId": "72530dfb-e8bf-4e16-b66b-31b33cd985fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "    import os # Import the os module\n",
        "    os.system(\"streamlit run /content/app.py --server.port 8501\")"
      ],
      "metadata": {
        "id": "Hc4pIq4lkl6V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "#genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "\n",
        "#output_dir = 'saliency_maps'\n",
        "#os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def generate_explanation(img_path, model_prediction, confidence):\n",
        "    prompt = f\"\"\"You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.\n",
        "    The saliency map was generated by a deep learning model that was trained to classify brain tumors\n",
        "    as either glioma, meningioma, pituitary, or no tumor.\n",
        "\n",
        "    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.\n",
        "\n",
        "    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.\n",
        "\n",
        "    In your response:\n",
        "    - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted\n",
        "    in light cyan, those are the regions where the model is focusing on.\n",
        "    - Explain possible reasons why the model made the prediction it did.\n",
        "    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'\n",
        "    in your explanation.\n",
        "    - Keep your explanation to 4 sentences max.\n",
        "\n",
        "    Let's think step by step about this. Verify step by step.\n",
        "    \"\"\"\n",
        "\n",
        "    img = PIL.Image.open(img_path)\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "    response = model.generate_content([prompt, img])\n",
        "\n",
        "    return response.text\n",
        "\n",
        "\n",
        "def generate_explanation_groq(img_path, model_prediction, confidence):\n",
        "    prompt = f\"\"\"You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.\n",
        "    The saliency map was generated by a deep learning model that was trained to classify brain tumors\n",
        "    as either glioma, meningioma, pituitary, or no tumor.\n",
        "\n",
        "    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.\n",
        "\n",
        "    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.\n",
        "\n",
        "    In your response:\n",
        "    - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted\n",
        "    in light cyan, those are the regions where the model is focusing on.\n",
        "    - Explain possible reasons why the model made the prediction it did.\n",
        "    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'\n",
        "    in your explanation.\n",
        "    - Keep your explanation to 4 sentences max.\n",
        "\n",
        "    Let's think step by step about this. Verify step by step.\n",
        "    \"\"\"\n",
        "\n",
        "    from groq import Groq\n",
        "    import base64\n",
        "\n",
        "\n",
        "    # Function to encode the image\n",
        "    def encode_image(img_path):\n",
        "       with open(img_path, \"rb\") as image_file:\n",
        "          return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    # Getting the base64 string\n",
        "    base64_image = encode_image(img_path)\n",
        "\n",
        "    #client = Groq(api_key=userdata.get('GROQ_API_KEY'))\n",
        "    client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": prompt },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.2-11b-vision-preview\",\n",
        "    )\n",
        "\n",
        "\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "output_dir = 'saliency_maps'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def generate_saliency_map(model, img_array, class_index, img_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "        img_tensor = tf.convert_to_tensor(img_array)\n",
        "        tape.watch(img_tensor)\n",
        "        predictions = model(img_tensor)\n",
        "        target_class = predictions[:, class_index]\n",
        "\n",
        "    gradients = tape.gradient(target_class, img_tensor)\n",
        "    gradients = tf.math.abs(gradients)\n",
        "    gradients = tf.reduce_max(gradients, axis=-1)\n",
        "    gradients = gradients.numpy().squeeze()\n",
        "\n",
        "    # Resize gradients to match original image size\n",
        "    gradients = cv2.resize(gradients, img_size)\n",
        "\n",
        "    # Create a circular mask for the brain area\n",
        "    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)\n",
        "    radius = min(center[0], center[1]) // 10\n",
        "    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]\n",
        "    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
        "\n",
        "    # Apply mask to gradients\n",
        "    gradients = gradients * mask\n",
        "\n",
        "    # Normalize only the brain area\n",
        "    brain_gradients = gradients[mask]\n",
        "    if brain_gradients.max() > brain_gradients.min():\n",
        "        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())\n",
        "    gradients[mask] = brain_gradients\n",
        "\n",
        "    # Apply a higher threshold\n",
        "    threshold = np.percentile(gradients[mask], 80)\n",
        "    gradients[gradients < threshold] = 0\n",
        "\n",
        "    # Apply more aggressive smoothing\n",
        "    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)\n",
        "\n",
        "    # Create a heatmap overlay with enhanced contrast\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize heatmap to match original image size\n",
        "    heatmap = cv2.resize(heatmap, img_size)\n",
        "\n",
        "    # Superimpose the heatmap on original image with increased opacity\n",
        "    original_img = image.img_to_array(img)\n",
        "    superimposed_img = heatmap * 0.7 + original_img * 0.3\n",
        "    superimposed_img = superimposed_img.astype(np.uint8)\n",
        "\n",
        "    img_path = os.path.join(output_dir, uploaded_file.name)\n",
        "    with open(img_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n",
        "\n",
        "    # Save the saliency map\n",
        "    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    return superimposed_img\n",
        "\n",
        "\n",
        "def load_xception_model(model_path):\n",
        "    img_shape = (299, 299, 3)\n",
        "\n",
        "    base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\",\n",
        "                                             input_shape=img_shape, pooling='max')\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dropout(rate=0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(rate=0.25),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.build((None,) + img_shape)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(Adamax(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy',\n",
        "                            Precision(),\n",
        "                            Recall()])\n",
        "\n",
        "    model.load_weights(model_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.title(\"Brain Tumor Classification\")\n",
        "\n",
        "st.write(\"Upload an image of a brain MRI scan to classify.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "\n",
        "    selected_model = st.radio(\n",
        "        \"Select Model\",\n",
        "        (\"Transfer Learning - Xception\", \"Custom CNN\")\n",
        "    )\n",
        "\n",
        "    if selected_model == \"Transfer Learning - Xception\":\n",
        "        #model = load_xception_model('/content/xception_model.weights.h5')\n",
        "        model = load_xception_model('/content/drive/MyDrive/W3_Headstarter_Acc_P3_Brain_Tumor_Classific_NNs_h5/xception_model.weights.h5')\n",
        "        img_size = (299, 299)\n",
        "    else:\n",
        "        #model = load_model('/content/cnn_model.h5')\n",
        "        model = load_model('/content/drive/MyDrive/W3_Headstarter_Acc_P3_Brain_Tumor_Classific_NNs_h5/cnn_model.h5')\n",
        "        img_size = (224, 224)\n",
        "\n",
        "    labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']\n",
        "    img = image.load_img(uploaded_file, target_size=img_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "\n",
        "    # Get the class with the highest probability\n",
        "    class_index = np.argmax(prediction[0])\n",
        "    result = labels[class_index]\n",
        "\n",
        "    st.write(f\"Predicted Class: {result}\")\n",
        "    st.write(\"Predictions:\")\n",
        "    for label, prob in zip(labels, prediction[0]):\n",
        "        st.write(f\"{label}: {prob:.4f}\")\n",
        "\n",
        "    saliency_map = generate_saliency_map(model, img_array, class_index, img_size)\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "      st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    with col2:\n",
        "      st.image(saliency_map, caption=\"Saliency Map\", use_column_width=True)\n",
        "\n",
        "\n",
        "    st.write(\"## Classification Results\")\n",
        "\n",
        "    result_container = st.container()\n",
        "    result_container = st.container()\n",
        "\n",
        "    result_container.markdown(\n",
        "    f\"\"\"\n",
        "    <div style=\"background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;\">\n",
        "        <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
        "            <div style=\"flex: 1; text-align: center;\">\n",
        "                <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Prediction</h3>\n",
        "                <p style=\"font-size: 36px; font-weight: 800; color: #FF0000; margin: 0;\">\n",
        "                    {result}\n",
        "                </p>\n",
        "            </div>\n",
        "            <div style=\"width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;\"></div>\n",
        "            <div style=\"flex: 1; text-align: center;\">\n",
        "                <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Confidence</h3>\n",
        "                <p style=\"font-size: 36px; font-weight: 800; color: #2196F3; margin: 0;\">\n",
        "                    {prediction[0][class_index]:.4%}\n",
        "                </p>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    # Prepare data for Plotly chart\n",
        "    probabilities = prediction[0]\n",
        "    sorted_indices = np.argsort(probabilities)[::-1]\n",
        "    sorted_labels = [labels[i] for i in sorted_indices]\n",
        "    sorted_probabilities = probabilities[sorted_indices]\n",
        "\n",
        "    # Create a Plotly bar chart\n",
        "    fig = go.Figure(go.Bar(\n",
        "    x=sorted_probabilities,\n",
        "    y=sorted_labels,\n",
        "    orientation='h',\n",
        "    marker_color=['red' if label == result else 'blue' for label in sorted_labels]\n",
        "    ))\n",
        "\n",
        "    # Customize the chart layout\n",
        "    fig.update_layout(\n",
        "    title='Probabilities for each class',\n",
        "    xaxis_title='Probability',\n",
        "    yaxis_title='Class',\n",
        "    height=400,\n",
        "    width=600,\n",
        "    yaxis=dict(autorange=\"reversed\")\n",
        "    )\n",
        "\n",
        "    # Add value labels to the bars\n",
        "    for i, prob in enumerate(sorted_probabilities):\n",
        "      fig.add_annotation(\n",
        "        x=prob,\n",
        "        y=i,\n",
        "        text=f'{prob:.4f}',\n",
        "        showarrow=False,\n",
        "        xshift=5\n",
        "        )\n",
        "\n",
        "    # Display the Plotly chart\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    #Wihout chosing the llms models\n",
        "    #saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n",
        "    #explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])\n",
        "\n",
        "    #st.write(\"# Explanation\")\n",
        "    #st.write(explanation)\n",
        "\n",
        "\n",
        "    selected_llm = st.radio(\n",
        "        \"Select LLM for explanation\",\n",
        "        (\"gemini-1.5-flash\", \"llama-3.2-11b-vision-preview\")\n",
        "    )\n",
        "\n",
        "    if selected_llm == \"gemini-1.5-flash\":\n",
        "        saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n",
        "        explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])\n",
        "\n",
        "        st.write(\"# Explanation\")\n",
        "        st.write(explanation)\n",
        "\n",
        "    else:\n",
        "        saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n",
        "        explanation = generate_explanation_groq(saliency_map_path, result, prediction[0][class_index])\n",
        "\n",
        "        st.write(\"# Explanation\")\n",
        "        st.write(explanation)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wA4gDakkl4E",
        "outputId": "194052b8-304d-4501-d61d-d218d3da4bc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "L6ssNS5WlPL8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Disconnect all existing tunnels\n",
        "for tunnel in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "\n",
        "# Now connect your new tunnel\n",
        "public_url = ngrok.connect(addr='8501', proto='http')\n",
        "\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNXV4-PdlUcE",
        "outputId": "1a03082e-1ae8-4452-be16-b0ab473a3924"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://9203-34-124-244-140.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "tunnels = ngrok.get_tunnels()\n",
        "for tunnel in tunnels:\n",
        "    print(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Cn_4rjQDlPOP",
        "outputId": "227e7538-145f-4d4a-e9d8-c93a2d42d39a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntunnels = ngrok.get_tunnels()\\nfor tunnel in tunnels:\\n    print(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config[\\'addr\\']}\")\\n    ngrok.disconnect(tunnel.public_url)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HKIZSwJ3kl8H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8BiKOBZkl-o"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}